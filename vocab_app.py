import os
import json
import sqlite3
import csv
import random
from datetime import datetime
from openai import OpenAI
import streamlit as st

# ========== é…ç½®éƒ¨åˆ† ==========
DB_PATH = "vocab.db"

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ========== æ•°æ®åº“ç›¸å…³å‡½æ•° ==========

def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼Œæ²¡æœ‰è¡¨å°±åˆ›å»ºï¼›æ—§åº“è‡ªåŠ¨è¡¥ä¸Š difficulty å­—æ®µã€‚"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """
        CREATE TABLE IF NOT EXISTS vocab (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            word TEXT NOT NULL,
            meaning_en TEXT,
            meaning_zh TEXT,
            example TEXT,
            topic TEXT,
            tag TEXT,
            difficulty INTEGER,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP
        );
        """
    )
    # æ—§åº“å¯èƒ½æ²¡æœ‰ difficulty å­—æ®µï¼Œè¿™é‡Œå°è¯•åŠ ä¸€åˆ—
    try:
        c.execute("ALTER TABLE vocab ADD COLUMN difficulty INTEGER;")
    except sqlite3.OperationalError:
        pass
    conn.commit()
    conn.close()


def insert_vocab_items(items, topic=None, tag=None, difficulty=None):
    """
    items: åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ dict:
        {
            "word": ...,
            "meaning_en": ...,
            "meaning_zh": ...,
            "example": ...
        }
    difficulty: 1~5 æˆ– None
    """
    if not items:
        return
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    for it in items:
        c.execute(
            """
            INSERT INTO vocab (word, meaning_en, meaning_zh, example, topic, tag, difficulty)
            VALUES (?, ?, ?, ?, ?, ?, ?);
            """,
            (
                it.get("word"),
                it.get("meaning_en"),
                it.get("meaning_zh"),
                it.get("example"),
                topic,
                tag,
                difficulty,
            ),
        )
    conn.commit()
    conn.close()


def get_random_items(limit=10, difficulty=None):
    """éšæœºæŠ½è¯ï¼›å¦‚æœä¼  difficultyï¼Œå°±æŒ‰ç”Ÿåƒ»ç¨‹åº¦ç­›é€‰ã€‚"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    if difficulty is None:
        c.execute(
            """
            SELECT id, word, meaning_en, meaning_zh, example, topic, tag, difficulty, created_at
            FROM vocab
            ORDER BY RANDOM()
            LIMIT ?;
            """,
            (limit,),
        )
    else:
        c.execute(
            """
            SELECT id, word, meaning_en, meaning_zh, example, topic, tag, difficulty, created_at
            FROM vocab
            WHERE difficulty = ?
            ORDER BY RANDOM()
            LIMIT ?;
            """,
            (difficulty, limit),
        )
    rows = c.fetchall()
    conn.close()
    return rows


def get_recent_items(limit=50):
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """
        SELECT id, word, meaning_en, meaning_zh, example, topic, tag, difficulty, created_at
        FROM vocab
        ORDER BY id DESC
        LIMIT ?;
        """,
        (limit,),
    )
    rows = c.fetchall()
    conn.close()
    return rows


def export_to_csv(filename="vocab_export.csv"):
    """å¯¼å‡ºæ‰€æœ‰è¯æ±‡åˆ° CSVï¼ŒåŒ…å« difficultyã€‚"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        """
        SELECT word, meaning_en, meaning_zh, example, topic, tag, difficulty, created_at
        FROM vocab
        ORDER BY id;
        """
    )
    rows = c.fetchall()
    conn.close()

    headers = [
        "word",
        "meaning_en",
        "meaning_zh",
        "example",
        "topic",
        "tag",
        "difficulty",
        "created_at",
    ]

    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(headers)
        writer.writerows(rows)

    return filename

# ========== GPT ç”Ÿæˆéƒ¨åˆ† ==========

def call_gpt_for_vocab(topic, num_items=10, difficulty=2, forbidden_words=None):
    """
    è®© GPT ç”Ÿæˆ JSON æ ¼å¼çš„ç”Ÿæ´»åœºæ™¯è¯æ±‡ã€‚
    difficulty: 1 (éå¸¸å¸¸ç”¨) ~ 5 (æ¯”è¾ƒç”Ÿåƒ»/é«˜çº§)
    forbidden_words: å·²å‡ºç°è¿‡çš„è¯åˆ—è¡¨ï¼Œè¦æ±‚ GPT é¿å…é‡å¤ã€‚
    """
    random_seed = random.randint(1, 1_000_000)

    forbidden_block = ""
    if forbidden_words:
        unique = sorted({w.strip() for w in forbidden_words if w})
        if unique:
            joined = ", ".join(unique[:200])  # é¿å…å¤ªé•¿
            forbidden_block = f"""
Important:
- Do NOT include any of these previously generated words or phrases (avoid exact matches):
  {joined}
- Prefer new vocabulary rather than repeating the same items.
"""

    prompt = f"""
You are an English tutor for a Chinese ESL student in the United States.

Generate {num_items} daily-life English words or short phrases
for the topic "{topic}", with rarity level {difficulty} on a 1â€“5 scale:

1 = very common, basic, used every day
2 = common but slightly more specific
3 = moderately uncommon but useful
4 = uncommon but natural in real conversations
5 = rare/advanced but practical and expressive

{forbidden_block}

Additional instructions:
- Every time this request is called, you MUST generate a NEW and DIFFERENT
  set of vocabulary, even if the topic and difficulty are the same.
- Use the random seed below to diversify your choice.
- Avoid only the most obvious textbook examples; explore more natural daily language.

Random seed for this generation: {random_seed}

Return ONLY valid JSON in this exact format (no explanation, no markdown):

[
  {{
    "word": "checkup",
    "meaning_en": "a medical examination to see if you are healthy",
    "meaning_zh": "ä½“æ£€ï¼›æ£€æŸ¥èº«ä½“",
    "example": "I scheduled a checkup with my doctor for next week."
  }}
]
"""
    resp = client.chat.completions.create(
        model="gpt-4.1",   # ä½¿ç”¨æ›´å¼ºæ¨¡å‹
        messages=[{"role": "user", "content": prompt}],
        temperature=0.8,
    )
    content = resp.choices[0].message.content.strip()
    return json.loads(content)


def call_gpt_for_phrasal_verbs(num_items=10, difficulty=2, forbidden_words=None):
    """
    è®© GPT ç”Ÿæˆ JSON æ ¼å¼çš„åŠ¨è¯çŸ­è¯­ï¼ˆphrasal verbsï¼‰ã€‚
    difficulty: 1 (å¸¸ç”¨) ~ 5 (ç”Ÿåƒ»/é«˜çº§)
    forbidden_words: å·²å‡ºç°è¿‡çš„çŸ­è¯­åˆ—è¡¨ï¼Œè¦æ±‚ GPT é¿å…é‡å¤ã€‚
    """
    random_seed = random.randint(1, 1_000_000)

    forbidden_block = ""
    if forbidden_words:
        unique = sorted({w.strip() for w in forbidden_words if w})
        if unique:
            joined = ", ".join(unique[:200])
            forbidden_block = f"""
Important:
- Do NOT include any of these previously generated phrasal verbs (avoid exact matches):
  {joined}
- Prefer new phrasal verbs rather than repeating the same items.
"""

    prompt = f"""
Generate {num_items} useful English phrasal verbs used in daily life,
with rarity level {difficulty} (1 = common/basic, 5 = rare/advanced).

Definitions:
1 = very common and basic (used every day)
2 = common but slightly more advanced
3 = moderately uncommon but helpful for fluency
4 = uncommon but expressive, more nuanced
5 = rare, advanced but still practical phrasal verbs

{forbidden_block}

Additional instructions:
- Every time this request is called, you MUST generate a NEW and DIFFERENT
  set of phrasal verbs, even with the same difficulty level.
- Use the random seed below to diversify your choice.
- Avoid only textbook-style examples; focus on natural spoken English.

Random seed for this generation: {random_seed}

Return ONLY valid JSON in this exact format (no explanation, no markdown):

[
  {{
    "word": "dress up",
    "meaning_en": "to put on nice or formal clothes",
    "meaning_zh": "ç››è£…æ‰“æ‰®",
    "example": "We have to dress up for the wedding this weekend."
  }}
]
"""
    resp = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
    )
    content = resp.choices[0].message.content.strip()
    return json.loads(content)

# ========== Streamlit ç•Œé¢éƒ¨åˆ† ==========

def page_generate_vocab():
    st.header("ğŸ”¤ ç”Ÿæˆç”Ÿæ´»åœºæ™¯è¯æ±‡")

    topic = st.text_input("ç”Ÿæ´»åœºæ™¯ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡éƒ½å¯ä»¥ï¼‰ï¼š", value="çœ‹ç—… / å»åŒ»é™¢")
    num_items = st.slider("ç”Ÿæˆå¤šå°‘ä¸ªè¯/çŸ­è¯­ï¼Ÿ", min_value=5, max_value=30, value=12, step=1)
    difficulty = st.slider("ç”Ÿåƒ»ç¨‹åº¦ (1 = éå¸¸å¸¸ç”¨, 5 = æ¯”è¾ƒç”Ÿåƒ»)", 1, 5, 2)

    # å‡†å¤‡å†å²å•è¯ï¼Œç”¨äºç¦æ­¢é‡å¤ï¼ˆæŒ‰ä¸»é¢˜åŒºåˆ†ï¼‰
    normalized_topic = topic.strip().lower()
    vocab_history = st.session_state.setdefault("vocab_history", {})
    forbidden_words = sorted(vocab_history.get(normalized_topic, set()))

    if st.button("âœ¨ ç”¨ GPT ç”Ÿæˆæ–°è¯æ±‡"):
        if not os.getenv("OPENAI_API_KEY"):
            st.error("æ²¡æœ‰æ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·å…ˆé…ç½® API Keyã€‚")
            return

        with st.spinner("æ­£åœ¨å‘ GPT è¯·æ±‚è¯æ±‡ï¼Œè¯·ç¨ç­‰..."):
            try:
                items = call_gpt_for_vocab(
                    topic,
                    num_items=num_items,
                    difficulty=difficulty,
                    forbidden_words=forbidden_words,
                )
            except Exception as e:
                st.error(f"è°ƒç”¨ GPT å‡ºé”™ï¼š{e}")
                return

        # æ›´æ–° session_state å†å² & æœ¬æ¬¡ç»“æœ
        st.session_state["last_vocab_items"] = items
        st.session_state["last_vocab_topic"] = topic
        st.session_state["last_vocab_difficulty"] = difficulty

        # æ›´æ–°å†å²ç¦æ­¢è¯åˆ—è¡¨
        hist_set = vocab_history.get(normalized_topic, set())
        for it in items:
            w = (it.get("word") or "").strip().lower()
            if w:
                hist_set.add(w)
        vocab_history[normalized_topic] = hist_set
        st.session_state["vocab_history"] = vocab_history

    # å¦‚æœæœ‰å†å²ç”Ÿæˆç»“æœï¼Œå°±å±•ç¤ºå‡ºæ¥
    items = st.session_state.get("last_vocab_items", None)
    if items:
        topic = st.session_state.get("last_vocab_topic", topic)
        difficulty = st.session_state.get("last_vocab_difficulty", difficulty)

        st.success(f"å·²ç”Ÿæˆ {len(items)} ä¸ªè¯æ±‡ï¼ˆä¸»é¢˜: {topic}ï¼Œéš¾åº¦ Level {difficulty}ï¼‰")
        save_all_clicked = st.button("ğŸ’¾ å°†è¿™æ‰¹è¯æ±‡å…¨éƒ¨ä¿å­˜åˆ°è¯åº“")

        for i, it in enumerate(items, start=1):
            st.markdown(f"### {i}. {it['word']}")
            st.write(f"- **è‹±æ–‡é‡Šä¹‰**: {it['meaning_en']}")
            st.write(f"- **ä¸­æ–‡é‡Šä¹‰**: {it['meaning_zh']}")
            st.write(f"- **ä¾‹å¥**: {it['example']}")

            # å•ç‹¬ä¿å­˜æŒ‰é’®
            if st.button("æ·»åŠ åˆ°æˆ‘çš„è¯åº“", key=f"add_vocab_{i}"):
                insert_vocab_items(
                    [it],
                    topic=topic,
                    tag=f"daily_vocab_{difficulty}",
                    difficulty=difficulty,
                )
                st.success(f"âœ… å·²æ·»åŠ ï¼š{it['word']}")

            st.write("---")

        # ä¸€é”®ä¿å­˜å…¨éƒ¨
        if save_all_clicked:
            insert_vocab_items(
                items,
                topic=topic,
                tag=f"daily_vocab_{difficulty}",
                difficulty=difficulty,
            )
            st.success("âœ… å½“å‰è¿™ä¸€æ‰¹è¯æ±‡å·²å…¨éƒ¨ä¿å­˜åˆ°è¯åº“ã€‚")


def page_generate_phrasal_verbs():
    st.header("ğŸ§© ç”ŸæˆåŠ¨è¯çŸ­è¯­ï¼ˆphrasal verbsï¼‰")

    num_items = st.slider("ç”Ÿæˆå¤šå°‘ä¸ªåŠ¨è¯çŸ­è¯­ï¼Ÿ", min_value=5, max_value=30, value=10, step=1)
    difficulty = st.slider("ç”Ÿåƒ»ç¨‹åº¦ (1 = å¸¸ç”¨, 5 = ç”Ÿåƒ»/é«˜çº§)", 1, 5, 2)

    # å‡†å¤‡å†å²çŸ­è¯­ï¼Œç”¨äºç¦æ­¢é‡å¤ï¼ˆæŒ‰éš¾åº¦åŒºåˆ†ï¼‰
    phrasal_history = st.session_state.setdefault("phrasal_history", {})
    forbidden_words = sorted(phrasal_history.get(difficulty, set()))

    if st.button("âœ¨ ç”¨ GPT ç”Ÿæˆæ–°çŸ­è¯­"):
        if not os.getenv("OPENAI_API_KEY"):
            st.error("æ²¡æœ‰æ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·å…ˆé…ç½® API Keyã€‚")
            return

        with st.spinner("æ­£åœ¨ç”ŸæˆåŠ¨è¯çŸ­è¯­ï¼Œè¯·ç¨ç­‰..."):
            try:
                items = call_gpt_for_phrasal_verbs(
                    num_items=num_items,
                    difficulty=difficulty,
                    forbidden_words=forbidden_words,
                )
            except Exception as e:
                st.error(f"è°ƒç”¨ GPT å‡ºé”™ï¼š{e}")
                return

        st.session_state["last_phrasal_items"] = items
        st.session_state["last_phrasal_difficulty"] = difficulty

        # æ›´æ–° phrasal å†å²
        hist_set = phrasal_history.get(difficulty, set())
        for it in items:
            w = (it.get("word") or "").strip().lower()
            if w:
                hist_set.add(w)
        phrasal_history[difficulty] = hist_set
        st.session_state["phrasal_history"] = phrasal_history

    items = st.session_state.get("last_phrasal_items", None)
    if items:
        difficulty = st.session_state.get("last_phrasal_difficulty", difficulty)
        st.success(f"å·²ç”Ÿæˆ {len(items)} ä¸ªåŠ¨è¯çŸ­è¯­ï¼ˆéš¾åº¦ Level {difficulty}ï¼‰")
        save_all_clicked = st.button("ğŸ’¾ å°†è¿™æ‰¹çŸ­è¯­å…¨éƒ¨ä¿å­˜åˆ°è¯åº“")

        for i, it in enumerate(items, start=1):
            st.markdown(f"### {i}. {it['word']}")
            st.write(f"- **è‹±æ–‡é‡Šä¹‰**: {it['meaning_en']}")
            st.write(f"- **ä¸­æ–‡é‡Šä¹‰**: {it['meaning_zh']}")
            st.write(f"- **ä¾‹å¥**: {it['example']}")

            if st.button("æ·»åŠ åˆ°æˆ‘çš„è¯åº“", key=f"add_phrasal_{i}"):
                insert_vocab_items(
                    [it],
                    topic="phrasal_verbs",
                    tag=f"phrasal_{difficulty}",
                    difficulty=difficulty,
                )
                st.success(f"âœ… å·²æ·»åŠ ï¼š{it['word']}")

            st.write("---")

        if save_all_clicked:
            insert_vocab_items(
                items,
                topic="phrasal_verbs",
                tag=f"phrasal_{difficulty}",
                difficulty=difficulty,
            )
            st.success("âœ… å½“å‰è¿™ä¸€æ‰¹åŠ¨è¯çŸ­è¯­å·²å…¨éƒ¨ä¿å­˜åˆ°è¯åº“ã€‚")


def page_review_quiz():
    st.header("ğŸ“š å¤ä¹  / å°æµ‹éªŒ")

    num_items = st.slider("æŠ½å¤šå°‘ä¸ªè¯æ¥å¤ä¹ ï¼Ÿ", min_value=5, max_value=30, value=10, step=1)
    difficulty_choice = st.selectbox(
        "æŒ‰ç”Ÿåƒ»ç¨‹åº¦ç­›é€‰ï¼ˆå¯é€‰ï¼‰ï¼š",
        ["å…¨éƒ¨", "1", "2", "3", "4", "5"],
        index=0,
    )

    if st.button("ğŸ¯ æŠ½é¢˜å¼€å§‹å¤ä¹ "):
        if difficulty_choice == "å…¨éƒ¨":
            diff = None
        else:
            diff = int(difficulty_choice)

        rows = get_random_items(limit=num_items, difficulty=diff)
        if not rows:
            st.warning("æ•°æ®åº“é‡Œè¿˜æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è¯æ±‡ï¼Œå…ˆå»â€œç”Ÿæˆè¯æ±‡â€é¡µé¢æ·»åŠ ä¸€äº›å§ã€‚")
            return

        for row in rows:
            _id, word, meaning_en, meaning_zh, example, topic, tag, difficulty, created_at = row
            st.markdown(f"### {word}")
            st.caption(
                f"ä¸»é¢˜: {topic or '-'} | æ ‡ç­¾: {tag or '-'} | "
                f"éš¾åº¦: {difficulty if difficulty is not None else '-'} | æ·»åŠ æ—¶é—´: {created_at}"
            )

            with st.expander("ğŸ‘‰ æ˜¾ç¤ºé‡Šä¹‰å’Œä¸­æ–‡"):
                st.write(f"**è‹±æ–‡é‡Šä¹‰**: {meaning_en}")
                st.write(f"**ä¸­æ–‡é‡Šä¹‰**: {meaning_zh}")
            with st.expander("ğŸ‘‰ æ˜¾ç¤ºä¾‹å¥"):
                st.write(example)
            st.write("---")


def page_recent_and_export():
    st.header("ğŸ—ƒ æœ€è¿‘æ·»åŠ çš„è¯æ±‡ & å¯¼å‡º CSV")

    limit = st.slider("æ˜¾ç¤ºæœ€è¿‘å¤šå°‘æ¡è¯æ±‡ï¼Ÿ", min_value=20, max_value=1000, value=100, step=20)
    rows = get_recent_items(limit=limit)

    if not rows:
        st.info("è¿˜æ²¡æœ‰ä»»ä½•è¯æ±‡ï¼Œå…ˆå»æ·»åŠ ä¸€äº›å§ï½")
    else:
        st.subheader(f"æœ€è¿‘æ·»åŠ çš„è¯æ±‡ï¼ˆæœ€å¤š {limit} æ¡ï¼‰")
        for row in rows:
            _id, word, meaning_en, meaning_zh, example, topic, tag, difficulty, created_at = row
            st.markdown(
                f"**{word}**  ï¼ˆä¸»é¢˜: {topic or '-'} / æ ‡ç­¾: {tag or '-'} / "
                f"éš¾åº¦: {difficulty if difficulty is not None else '-'}ï¼‰"
            )
            st.caption(f"æ·»åŠ æ—¶é—´: {created_at}")
            st.write(f"- è‹±æ–‡é‡Šä¹‰: {meaning_en}")
            st.write(f"- ä¸­æ–‡é‡Šä¹‰: {meaning_zh}")
            st.write(f"- ä¾‹å¥: {example}")
            st.write("---")

    st.subheader("ğŸ“¤ å¯¼å‡ºä¸º CSV æ–‡ä»¶")
    if st.button("å¯¼å‡º vocab_export.csv"):
        filename = export_to_csv()
        st.success(f"å·²å¯¼å‡ºä¸º {filename}ï¼Œåœ¨å½“å‰ç›®å½•ä¸‹å¯ä»¥æ‰¾åˆ°è¿™ä¸ªæ–‡ä»¶ã€‚")


def main():
    st.set_page_config(page_title="æˆ‘çš„è‹±è¯­èƒŒå•è¯å°åŠ©æ‰‹", page_icon="ğŸ“˜", layout="wide")
    init_db()

    st.sidebar.title("ğŸ“˜ èƒŒå•è¯ App")
    page = st.sidebar.radio(
        "é€‰æ‹©é¡µé¢ï¼š",
        (
            "ç”Ÿæˆç”Ÿæ´»åœºæ™¯è¯æ±‡",
            "ç”ŸæˆåŠ¨è¯çŸ­è¯­",
            "å¤ä¹  / å°æµ‹éªŒ",
            "æŸ¥çœ‹æœ€è¿‘ & å¯¼å‡º CSV",
        ),
    )

    if page == "ç”Ÿæˆç”Ÿæ´»åœºæ™¯è¯æ±‡":
        page_generate_vocab()
    elif page == "ç”ŸæˆåŠ¨è¯çŸ­è¯­":
        page_generate_phrasal_verbs()
    elif page == "å¤ä¹  / å°æµ‹éªŒ":
        page_review_quiz()
    elif page == "æŸ¥çœ‹æœ€è¿‘ & å¯¼å‡º CSV":
        page_recent_and_export()


if __name__ == "__main__":
    main()
